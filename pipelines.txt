Overview over the employed data processing pipelines.

Corpora:
Training corpus -   the training portion of F+L's BBC news data set, minus the 240 documents in the development corpus
Development corpus  -   a random selection of 240 training articles
Test corpus -   the testing portion of F+L's BBC news data set
Background corpus   -   a collection of documents used to train the trigram component

Pipeline 1
Goal:               Train a LDA model on the core content data
Data used:          Training corpus (documents + captions + images)
Notes:              n/a
Degrees of freedom: t in LDA, k in k-means, word filter threshold T
Parameters to try:  (t in {100, 200, 350, 500, 750, 1000}, k in {250, 500, 750, 1000}), T = 5

Steps:
For the documents and captions:
(D_0 documents only)  remove HTML tags from documents
T_1 apply PoS-tagging (TreeTagger) to all data items
T_2 filter the PoS tags, keep only nouns, verbs, and adjectives
T_3 build filter vocabulary (BoW of all data)
T_4 filter files with filter vocabulary leaving out all terms that occur < 5 times

For the images:
I_0 transform .jpg to .pgm
I_1 extract SIFT from all images
I_2_reduce  train k-means model(s) on all SIFT data
I_3 compute visiterms for all images using the k-means model

For all data items:
A_1_reduce  build a LDA corpus from all data files, combining words from documents and captions with visiterms from images
A_2 train LDA model(s) from the constructed corpus(corpora)




Pipeline 2
Goal:               Train a trigram language model on texts
Data used:          Training corpus (documents + captions), background corpus
Notes:              F+L train with SRI toolkit. I think they thus do Kneser-Ney smoothing
Degrees of freedom: From smoothing techniques

Steps:
D_0 remove HTML/SGML/etc tags from documents to obtain raw text
T_1 tokenize the texts
T_2 build sentences from texts
T_3 add sentence start and sentence end tokens to sentences
T_4 build count trees for M = 1
T_5 build count trees for M = 2, with KN smoothing
T_6 build count trees for M = 3, with KN smoothing




Pipeline 3
Goal:           Train the conditional probability component
Data used:      Training corpus (documents + captions)
Notes:          This should probably be smoothed
Degrees of freedom: Smoothing, probably simple add-epsilon, then epsilon
Parameters to try:  epsilon = 1e-5

Steps:
D_0 remove HTML from documents
T_1 tokenize the texts
T_2 build sentences from texts
T_3 add sentence start and sentence end tokens to sentences
T_4_reduce  count the number of occurrences and do the MLE




Pipeline 4
Goal:           Train length model(s)
Data used:      Training corpus (documents + captions), or development corpus (documents + captions)
Notes:          It seems likely that F+L tried to minimize TER on the development corpus
Degrees of freedom: mean and variance of the Gaussian, alternatively choice of model, whether or not to train on captions and documents or only captions

Steps:
D_0 remove HTML from documents
T_1 tokenize the texts
T_2 build sentences from texts
T_3 add sentence start and sentence end tokens to sentences
T_4_reduce  do the MLE for a Gaussian on the sentences




Pipeline 5
Goal:           Train the class-based global trigram language model
Data used:      Training corpus
Notes:          
Degrees of freedom: number of classes C
Parameters to try:  C = 1000

Steps:
D_0 remove HTML from documents
T_1 tokenize the texts
T_2 build sentences from texts
T_3 add sentence start and sentence end tokens to sentences
T_4 build M = 2 count tree from all texts
T_5 apply the clustering script





Pipeline 6
Goal:           Choose training and background documents such that the perplexity of the trigram LM becomes minimal
Data used:      Test corpus for optimization, training + background corpora for choice of documents
Notes:          Perplexity can only be measured on the full documents, as in the test set, we have no captions. Alternatively, we could try to find a selection that overall fits best (from the development set)
Degrees of freedom: perplexity threshold P
Parameters to try:  P in {-10, -5, -1, 0, 1, 5, 10}

Steps:
D_0 remove HTML from documents
T_1 tokenize the texts
T_2 build sentences from texts
T_3 add sentence start and sentence end tokens to sentences
T_4 for each test document + caption, run the perplexity script and store the scores for each document in training and background corpus
T_5 for each test document, build a M = 1 count tree from the selection resulting from the choice of P
T_6 for each test document, build a KN-smoothed M = 2 count tree
T_7 for each test document, build a KN-smoothed M = 3 count tree





